{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfPQC9rUj1yg"
      },
      "source": [
        "[![Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/giordamaug/EG-identification---Data-Science-in-App-Springer/blob/main/notebook/EssentialGenes_Karateclub.ipynb)\n",
        "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/giordamaug/EG-identification---Data-Science-in-App-Springer/main?filepath=notebook%2FEssentialGenes_Karateclub.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNgwF_IjTjNq"
      },
      "source": [
        "# Loading required libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgVRqVeuq5GN"
      },
      "source": [
        "### Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "90eWJsb5q9j0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kfac 0.2.3 requires tensorflow-probability==0.8, but you have tensorflow-probability 0.7.0 which is incompatible.\n",
            "bamboolib 1.26.0 requires cryptography<3.0.0,>=2.6.1, but you have cryptography 36.0.0 which is incompatible.\n",
            "bamboolib 1.26.0 requires scikit-learn<1.0.0,>=0.20.2, but you have scikit-learn 1.0.2 which is incompatible.\n",
            "bamboolib 1.26.0 requires seaborn<0.11,>=0.10, but you have seaborn 0.11.2 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "if not IN_COLAB:\n",
        "    !pip install -q karateclub\n",
        "    !pip install -q pandas\n",
        "    !pip install -q sklearn\n",
        "    !pip install -q imblearn\n",
        "    !pip install -q xgboost\n",
        "    !pip install -q tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ddc1yRocTjNr"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "def set_seed(seed=1):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwXYNEIFff-l"
      },
      "source": [
        "# Download dataset from Github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykT1KO_4eqvK",
        "outputId": "75c2c1dd-52f1-4c0d-e1f4-8393575b0887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: wget\n",
            "zsh:1: command not found: wget\n",
            "zsh:1: command not found: wget\n",
            "zsh:1: command not found: wget\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/giordamaug/EG-identification---Data-Science-in-App-Springer/main/data/ppi.csv\n",
        "!wget https://raw.githubusercontent.com/giordamaug/EG-identification---Data-Science-in-App-Springer/main/data/labels.csv\n",
        "!wget https://raw.githubusercontent.com/giordamaug/EG-identification---Data-Science-in-App-Springer/main/data/bio_attributes.csv\n",
        "#!wget https://raw.githubusercontent.com/giordamaug/EG-identification---Data-Science-in-App-Springer/main/data/net_attributes.csv   you don't need it\n",
        "!wget https://raw.githubusercontent.com/giordamaug/EG-identification---Data-Science-in-App-Springer/main/data/gtex_attributes.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqYLkDA1yW-K"
      },
      "source": [
        "# Load the label\n",
        "Only a subset of genes are selected for classification:\n",
        "+ genes belonging to CS0 group, that are labeled as Essential (E);\n",
        "+ genes belonging to CS6, CS7, ..., CS9 groups, that are labeled as Not-Essential (NE).\n",
        "\n",
        "All remaining genes belong to intermediate groups (CS1-CS5) and are considered undetermined (label ND) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahZH3I5SyW-K",
        "outputId": "5ab95e5a-e602-49b3-dd02-5abdf20d3f0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected 3814 genes\n"
          ]
        }
      ],
      "source": [
        "labels = pd.read_csv(\"labels.csv\", index_col='name')\n",
        "labels = labels[labels[\"CS0_vs_CS6-9\"].isin(['E', 'NE']) == True]       # drop any gene with undefined (ND) label\n",
        "genes = labels.index.values                                             # get genes with defined labels (E or NE)\n",
        "print(f'Selected {len(genes)} genes')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DzCmBgbj1yn"
      },
      "source": [
        "## Encode the labels\n",
        "String labels E and Ne are respectively encoded to 0 and 1.\n",
        "The array `y` containes numeric labels of genes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBkOf7R0j1yo",
        "outputId": "bce09d0f-1fbd-4a35-aa65-4257c54d19f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'E': 0, 'NE': 1} Counter({1: 3069, 0: 745})\n"
          ]
        }
      ],
      "source": [
        "from sklearn import preprocessing\n",
        "from collections import Counter\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "y = encoder.fit_transform(labels['CS0_vs_CS6-9'].values)  \n",
        "classes_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
        "print(classes_mapping, Counter(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vmbko7ys1m-d"
      },
      "source": [
        "# Load attributes to be used\n",
        "We identified three sets of attributes:\n",
        "1. bio attributes, related to gene information (such as, expression, etc.)\n",
        "2. net attributes, derived from role of gene/node in the network (such as, degree, centrality, etc.)\n",
        "3. GTEX-* attribute, additional biological information of genes \n",
        "Based on user selection, the node attributes are appended in a single matrix of attributes (`x`)\n",
        "\n",
        "In the attribute matrix `x` there can be NaN or Infinite values. They are corrected as it follow:\n",
        "+ NaN is replaced by the mean in the attribute range, \n",
        "+ Infinte value is replaced by the maximum in the range.\n",
        "\n",
        "After Nan and Infinite values fixing, the attributes are normalized with Z-score or MinMax normalization functions.\n",
        "\n",
        "At the end, only nodes (genes) with E or NE labels are selected for the classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1eTV5Ky2R9_",
        "outputId": "8be77c93-6bb6-491a-e287-125cc4f8419d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 15919 NaN values and 0 Infinite values\n",
            "X attributes normalization (zscore)...\n",
            "New attribute matrix x(3814, 119)\n"
          ]
        }
      ],
      "source": [
        "#@title Choose attributes { form-width: \"20%\" }\n",
        "normalize_node = \"zscore\" #@param [\"\", \"zscore\", \"minmax\"]\n",
        "bio = True #@param {type:\"boolean\"}\n",
        "gtex = True #@param {type:\"boolean\"}\n",
        "net = True #@param {type:\"boolean\"}\n",
        "variable_name = \"bio\"\n",
        "bio_df = pd.read_csv(\"bio_attributes.csv\", index_col='name') if bio else pd.DataFrame()\n",
        "gtex_df = pd.read_csv(\"gtex_attributes.csv\", index_col='name') if gtex else pd.DataFrame()\n",
        "net_df = pd.read_csv(\"net_attributes.csv\", index_col='name') if net else pd.DataFrame()\n",
        "x = pd.concat([bio_df, gtex_df, net_df], axis=1)\n",
        "print(f'Found {x.isnull().sum().sum()} NaN values and {np.isinf(x).values.sum()} Infinite values')\n",
        "for col in x.columns[x.isna().any()].tolist():\n",
        "  mean_value=x[col].mean()          # Replace NaNs in column with the mean of values in the same column\n",
        "  if mean_value is not np.nan:\n",
        "    x[col].fillna(value=mean_value, inplace=True)\n",
        "  else:                             # otherwise, if the mean is NaN, remove the column\n",
        "    x = x.drop(col, 1)\n",
        "if normalize_node == 'minmax':\n",
        "  print(\"X attributes normalization (minmax)...\")\n",
        "  x = (x-x.min())/(x.max()-x.min())\n",
        "elif normalize_node == 'zscore':\n",
        "  print(\"X attributes normalization (zscore)...\")\n",
        "  x = (x-x.mean())/x.std()\n",
        "x = x.loc[genes]\n",
        "print(f'New attribute matrix x{x.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGZqjWBcmNM6"
      },
      "source": [
        "# Load the PPI+MET network\n",
        "The PPI networks is loaded from a CSV file, where\n",
        "*   `A` is the column name for edge source (gene name)\n",
        "*   `B` is the column name for edge target (gene name)\n",
        "*   `weight` is the column name for edge weight\n",
        "Only some method use the PPI netoworks, as an example all GCN methods, and Node2Vec.\n",
        "\n",
        "The PPI+MET network is reduced by removing genes with undetermined labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ku9EUnJfmMF4"
      },
      "outputs": [],
      "source": [
        "ppi = pd.read_csv('ppi.csv')                                               # read PPI+MET network from CSV file\n",
        "ppi = ppi.loc[((ppi['A'].isin(genes)) & (ppi['B'].isin(genes)))]           # reduce network only to selected nodes/genes\n",
        "idxlbl = labels.reset_index(drop=True)\n",
        "idxlbl['name'] = labels.index\n",
        "map_gene_to_idx = { v['name']: i  for i,v in idxlbl.to_dict('Index').items() }\n",
        "vfunc = np.vectorize(lambda t: map_gene_to_idx[t])\n",
        "edges_index = torch.from_numpy(vfunc(ppi[['A','B']].to_numpy().T)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Network embedding with Karateclub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAkzHzMYbAQh"
      },
      "source": [
        "# k-fold cross validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2bmY_k2KlE_"
      },
      "source": [
        "### Validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bXIozL_bC_x"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, KFold, train_test_split\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import *\n",
        "\n",
        "set_seed(1)\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "NFOLDS = 5\n",
        "LR = 1e-2\n",
        "WEIGHT_DECAY = 5e-4\n",
        "EPOCHS = 50\n",
        "\n",
        "X = torch.tensor(x.to_numpy(), dtype=torch.float)\n",
        "kf = KFold(n_splits=NFOLDS)\n",
        "cma = np.array([[0,0],[0,0]])\n",
        "columns_names = [\"Accuracy\",\"BA\", \"Sensitivity\", \"Specificity\",\"MCC\", 'CM']\n",
        "scores = pd.DataFrame(columns=columns_names)\n",
        "mm = np.array([], dtype=np.int)\n",
        "predictions = np.array([])\n",
        "for fold, (train_index, test_idx) in enumerate(tqdm(kf.split(np.arange(len(X))), total=kf.get_n_splits(), desc=f\"{NFOLDS}-fold\")):\n",
        "    train_idx, val_idx = train_test_split(train_index, test_size=0.05, stratify=y[train_index])\n",
        "    mm = np.concatenate((mm, test_idx))\n",
        "    train_y = torch.tensor(y[train_idx], dtype=torch.float)\n",
        "    val_y = torch.tensor(y[val_idx], dtype=torch.float)\n",
        "    test_y = torch.tensor(y[test_idx], dtype=torch.float).to(DEVICE)\n",
        "    train_x = torch.tensor(X[train_idx], dtype=torch.float).to(DEVICE)\n",
        "    val_x = torch.tensor(X[val_idx], dtype=torch.float).to(DEVICE)\n",
        "    test_x = torch.tensor(X[test_idx], dtype=torch.float).to(DEVICE)\n",
        "    probs = n2v_fit_predict(edges_index, X, train_y, train_idx, val_y, val_idx, test_idx, epochs=EPOCHS, log=False)\n",
        "    preds = (probs > 0.5) * 1\n",
        "    predictions = np.concatenate((predictions, preds.ravel()))\n",
        "    cm = confusion_matrix(test_y.cpu().numpy(),preds)\n",
        "    cma += cm\n",
        "    scores = scores.append(pd.DataFrame([[accuracy_score(test_y.cpu().numpy(), preds), balanced_accuracy_score(test_y.cpu().numpy(), preds), \n",
        "        cm[0,0]/(cm[0,0]+cm[0,1]), cm[1,1]/(cm[1,0]+cm[1,1]), \n",
        "        matthews_corrcoef(test_y.cpu().numpy(), preds), cm]], columns=columns_names, index=[fold]))\n",
        "df_scores = pd.DataFrame(scores.mean(axis=0)).T\n",
        "df_scores.index=[f'N2V']\n",
        "df_scores['CM'] = [cma]\n",
        "df_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TsJPJYWVKWo"
      },
      "source": [
        "# Print predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7Q2gF8t4p12"
      },
      "outputs": [],
      "source": [
        "p = np.zeros(len(y))\n",
        "p[mm] = predictions\n",
        "labels['predictions'] = ['NE' if x>0 else 'E' for x in p]\n",
        "labels"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "EssentialGenes_N2VMLP.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "bc6e667b201477635ba32fc377e71e93fe0ce3fc2d2fb508931525558f52d375"
    },
    "kernelspec": {
      "display_name": "Python 3.8.3 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

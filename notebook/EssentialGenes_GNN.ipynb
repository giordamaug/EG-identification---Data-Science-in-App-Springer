{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfPQC9rUj1yg"
      },
      "source": [
        "[![Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/giordamaug/EG-identification---Data-Science-in-App-Springer/blob/main/notebook/EssentialGenes_GNN.ipynb)\n",
        "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/giordamaug/EG-identification---Data-Science-in-App-Springer/main?filepath=notebook%2FEssentialGenes_GNN.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNgwF_IjTjNq"
      },
      "source": [
        "# Loading required libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgVRqVeuq5GN"
      },
      "source": [
        "### Install Pytorch libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90eWJsb5q9j0",
        "outputId": "e07f31d0-99bf-4349-eb53-e941af0f4b41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.11.0+cu113.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 2.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.11.0+cu113.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.13\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.11.0+cu113.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 2.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.11.0+cu113.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (750 kB)\n",
            "\u001b[K     |████████████████████████████████| 750 kB 2.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.4.tar.gz (407 kB)\n",
            "\u001b[K     |████████████████████████████████| 407 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.8)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616603 sha256=f98628f43f8660a7e8329de49a6d41ea6648393e40a866884f816137c3640cff\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/a6/a4/ca18c3051fcead866fe7b85700ee2240d883562a1bc70ce421\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.0.4\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "if not IN_COLAB:\n",
        "    !pip install -q pandas\n",
        "    !pip install -q pandas\n",
        "    !pip install -q sklearn\n",
        "    !pip install -q imblearn\n",
        "    !pip install -q xgboost\n",
        "    !pip install -q tqdm\n",
        "    !conda install -y pytorch torchvision -c pytorch\n",
        "\n",
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ddc1yRocTjNr"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "def set_seed(seed=1):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwXYNEIFff-l"
      },
      "source": [
        "# Download dataset from Github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykT1KO_4eqvK",
        "outputId": "d25f2eb8-e705-4a96-da0c-8bbbdc50a3fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-05-04 13:15:21--  https://raw.githubusercontent.com/giordamaug/EG-identification---Data-Science-in-App-Springer/main/data/ppi.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3966521 (3.8M) [text/plain]\n",
            "Saving to: ‘ppi.csv’\n",
            "\n",
            "ppi.csv             100%[===================>]   3.78M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2022-05-04 13:15:21 (49.7 MB/s) - ‘ppi.csv’ saved [3966521/3966521]\n",
            "\n",
            "--2022-05-04 13:15:21--  https://raw.githubusercontent.com/giordamaug/EG-identification---Data-Science-in-App-Springer/main/data/labels.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 237495 (232K) [text/plain]\n",
            "Saving to: ‘labels.csv’\n",
            "\n",
            "labels.csv          100%[===================>] 231.93K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-05-04 13:15:21 (8.64 MB/s) - ‘labels.csv’ saved [237495/237495]\n",
            "\n",
            "--2022-05-04 13:15:21--  https://raw.githubusercontent.com/giordamaug/EG-identification---Data-Science-in-App-Springer/main/data/bio_attributes.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1234495 (1.2M) [text/plain]\n",
            "Saving to: ‘bio_attributes.csv’\n",
            "\n",
            "bio_attributes.csv  100%[===================>]   1.18M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-05-04 13:15:22 (21.1 MB/s) - ‘bio_attributes.csv’ saved [1234495/1234495]\n",
            "\n",
            "--2022-05-04 13:15:22--  https://raw.githubusercontent.com/giordamaug/EG-identification---Data-Science-in-App-Springer/main/data/net_attributes.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2012067 (1.9M) [text/plain]\n",
            "Saving to: ‘net_attributes.csv’\n",
            "\n",
            "net_attributes.csv  100%[===================>]   1.92M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-05-04 13:15:22 (32.6 MB/s) - ‘net_attributes.csv’ saved [2012067/2012067]\n",
            "\n",
            "--2022-05-04 13:15:22--  https://raw.githubusercontent.com/giordamaug/EG-identification---Data-Science-in-App-Springer/main/data/gtex_attributes.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6882898 (6.6M) [text/plain]\n",
            "Saving to: ‘gtex_attributes.csv’\n",
            "\n",
            "gtex_attributes.csv 100%[===================>]   6.56M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2022-05-04 13:15:22 (81.6 MB/s) - ‘gtex_attributes.csv’ saved [6882898/6882898]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/giordamaug/EG-identification---Data-Science-in-App-Springer/main/data/ppi.csv\n",
        "!wget https://raw.githubusercontent.com/giordamaug/EG-identification---Data-Science-in-App-Springer/main/data/labels.csv\n",
        "!wget https://raw.githubusercontent.com/giordamaug/EG-identification---Data-Science-in-App-Springer/main/data/bio_attributes.csv\n",
        "!wget https://raw.githubusercontent.com/giordamaug/EG-identification---Data-Science-in-App-Springer/main/data/net_attributes.csv\n",
        "!wget https://raw.githubusercontent.com/giordamaug/EG-identification---Data-Science-in-App-Springer/main/data/gtex_attributes.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqYLkDA1yW-K"
      },
      "source": [
        "# Load the label\n",
        "Only a subset of genes are selected for classification:\n",
        "+ genes belonging to CS0 group, that are labeled as Essential (E);\n",
        "+ genes belonging to CS6, CS7, ..., CS9 groups, that are labeled as Not-Essential (NE).\n",
        "\n",
        "All remaining genes belong to intermediate groups (CS1-CS5) and are considered undetermined (label ND) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahZH3I5SyW-K",
        "outputId": "64c772e5-473c-4363-d1e2-ae9b555d59da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected 3814 genes\n"
          ]
        }
      ],
      "source": [
        "labels = pd.read_csv(\"labels.csv\", index_col='name')\n",
        "labels = labels[labels[\"CS0_vs_CS6-9\"].isin(['E', 'NE']) == True]       # drop any gene with undefined (ND) label\n",
        "genes = labels.index.values                                             # get genes with defined labels (E or NE)\n",
        "print(f'Selected {len(genes)} genes')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DzCmBgbj1yn"
      },
      "source": [
        "## Encode the labels\n",
        "String labels E and Ne are respectively encoded to 0 and 1.\n",
        "The array `y` containes numeric labels of genes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBkOf7R0j1yo",
        "outputId": "bcd0df5a-0bd5-4b25-a34c-2db18f9beb19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'E': 0, 'NE': 1} Counter({1: 3069, 0: 745})\n"
          ]
        }
      ],
      "source": [
        "from sklearn import preprocessing\n",
        "from collections import Counter\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "y = encoder.fit_transform(labels['CS0_vs_CS6-9'].values)  \n",
        "classes_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
        "print(classes_mapping, Counter(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vmbko7ys1m-d"
      },
      "source": [
        "# Load attributes to be used\n",
        "We identified three sets of attributes:\n",
        "1. bio attributes, related to gene information (such as, expression, etc.)\n",
        "2. net attributes, derived from role of gene/node in the network (such as, degree, centrality, etc.)\n",
        "3. GTEX-* attribute, additional biological information of genes \n",
        "Based on user selection, the node attributes are appended in a single matrix of attributes (`x`)\n",
        "\n",
        "In the attribute matrix `x` there can be NaN or Infinite values. They are corrected as it follow:\n",
        "+ NaN is replaced by the mean in the attribute range, \n",
        "+ Infinte value is replaced by the maximum in the range.\n",
        "\n",
        "After Nan and Infinite values fixing, the attributes are normalized with Z-score or MinMax normalization functions.\n",
        "\n",
        "At the end, only nodes (genes) with E or NE labels are selected for the classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1eTV5Ky2R9_",
        "outputId": "d4829810-de9e-48cb-9e80-8316d5d4319b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 15919 NaN values and 0 Infinite values\n",
            "X attributes normalization (zscore)...\n",
            "New attribute matrix x(3814, 119)\n"
          ]
        }
      ],
      "source": [
        "#@title Choose attributes { form-width: \"20%\" }\n",
        "normalize_node = \"zscore\" #@param [\"\", \"zscore\", \"minmax\"]\n",
        "bio = True #@param {type:\"boolean\"}\n",
        "gtex = True #@param {type:\"boolean\"}\n",
        "net = True #@param {type:\"boolean\"}\n",
        "variable_name = \"bio\"\n",
        "bio_df = pd.read_csv(\"bio_attributes.csv\", index_col='name') if bio else pd.DataFrame()\n",
        "gtex_df = pd.read_csv(\"gtex_attributes.csv\", index_col='name') if gtex else pd.DataFrame()\n",
        "net_df = pd.read_csv(\"net_attributes.csv\", index_col='name') if net else pd.DataFrame()\n",
        "x = pd.concat([bio_df, gtex_df, net_df], axis=1)\n",
        "print(f'Found {x.isnull().sum().sum()} NaN values and {np.isinf(x).values.sum()} Infinite values')\n",
        "for col in x.columns[x.isna().any()].tolist():\n",
        "  mean_value=x[col].mean()          # Replace NaNs in column with the mean of values in the same column\n",
        "  if mean_value is not np.nan:\n",
        "    x[col].fillna(value=mean_value, inplace=True)\n",
        "  else:                             # otherwise, if the mean is NaN, remove the column\n",
        "    x = x.drop(col, 1)\n",
        "if normalize_node == 'minmax':\n",
        "  print(\"X attributes normalization (minmax)...\")\n",
        "  x = (x-x.min())/(x.max()-x.min())\n",
        "elif normalize_node == 'zscore':\n",
        "  print(\"X attributes normalization (zscore)...\")\n",
        "  x = (x-x.mean())/x.std()\n",
        "x = x.loc[genes]\n",
        "print(f'New attribute matrix x{x.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGZqjWBcmNM6"
      },
      "source": [
        "# Load the PPI+MET network\n",
        "The PPI networks is loaded from a CSV file, where\n",
        "*   `A` is the column name for edge source (gene name)\n",
        "*   `B` is the column name for edge target (gene name)\n",
        "*   `weight` is the column name for edge weight\n",
        "Only some method use the PPI netoworks, as an example all GCN methods, and Node2Vec.\n",
        "\n",
        "The PPI+MET network is reduced by removing genes with undetermined labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ku9EUnJfmMF4"
      },
      "outputs": [],
      "source": [
        "ppi = pd.read_csv('ppi.csv')                                               # read PPI+MET network from CSV file\n",
        "ppi = ppi.loc[((ppi['A'].isin(genes)) & (ppi['B'].isin(genes)))]           # reduce network only to selected nodes/genes\n",
        "idxlbl = labels.reset_index(drop=True)\n",
        "idxlbl['name'] = labels.index\n",
        "map_gene_to_idx = { v['name']: i  for i,v in idxlbl.to_dict('Index').items() }\n",
        "vfunc = np.vectorize(lambda t: map_gene_to_idx[t])\n",
        "edges_index = torch.from_numpy(vfunc(ppi[['A','B']].to_numpy().T)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1Hl0h5sKPVW"
      },
      "source": [
        "## Normalize edge weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rOKgNteJ3KEn"
      },
      "outputs": [],
      "source": [
        "#@title Edge normalization { form-width: \"30%\" }\n",
        "normalize_edge = \"minmax\" #@param [\"\", \"zscore\", \"minmax\"]\n",
        "if normalize_edge == 'minmax':\n",
        "    maximum = ppi.loc[ppi['weight'] != np.inf, 'weight'].max()   # get max other than infinity\n",
        "    minimum = ppi.loc[ppi['weight'] != np.nan, 'weight'].min()   # get min other than NaN\n",
        "    ppi['weight'].replace(np.inf,maximum,inplace=True)             # replace ininity with max\n",
        "    ppi['weight'].replace(np.nan,minimum,inplace=True)             # replace NaN with min\n",
        "    ppi['weight'] = (ppi['weight'] - minimum) / (maximum - minimum)\n",
        "elif normalize_edge == 'zscore':\n",
        "    ppi['weight'] = (ppi['weight'] - ppi['weight'].mean()) / ppi['weight'].std()    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjmGrRxKqYU5"
      },
      "source": [
        "# Build PyG storage for network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T0ncbRhqYU5",
        "outputId": "b39ef4bb-d820-4a41-dddb-92ae3ca782b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Data(x=[3814, 119], edge_index=[2, 107513], edge_attr=[107513], y=[3814], num_classes=2, train_mask=[3814], val_mask=[3814], test_mask=[3814], train_idx=[2314], val_idx=[500], test_idx=[1000])\n",
            "===========================================================================================================\n",
            "Number of nodes: 3814\n",
            "Number of node features: 119\n",
            "Number of {'E': 0, 'NE': 1} classes: 2\n",
            "Class distritions: Counter({1: 3069, 0: 745})\n",
            "Number of edges: 107513\n",
            "Nodes indices: [   0    1    2 ... 3811 3812 3813]\n",
            "Average node degree: 28.19\n",
            "Number of training nodes: 2314\n",
            "Training node indices: tensor([   0,    1,    2,  ..., 3809, 3812, 3813])\n",
            "Training node label rate: 0.61\n",
            "Has isolated nodes: True\n",
            "Has edge weights: tensor([0.0413, 0.0338, 0.0395,  ..., 0.0003, 0.0066, 0.0047])\n",
            "Has self-loops: False\n",
            "Is directed: True\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing\n",
        "from collections import Counter\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.transforms import RandomNodeSplit\n",
        "import torch.nn.functional as F\n",
        "classes_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
        "data = Data(x=torch.from_numpy(x.to_numpy()).float(), edge_index=edges_index, edge_attr=torch.from_numpy(ppi['weight'].values).float(), y = torch.from_numpy(y))\n",
        "data.num_classes = len(np.unique(y))\n",
        "tfs =  RandomNodeSplit()\n",
        "tfs(data)\n",
        "\n",
        "train_indices = np.arange(0,len(data.x))\n",
        "data.train_idx = torch.tensor(train_indices[data.train_mask], dtype=torch.long)\n",
        "data.val_idx = torch.tensor(train_indices[data.val_mask], dtype=torch.long)\n",
        "data.test_idx = torch.tensor(train_indices[data.test_mask], dtype=torch.long)\n",
        "\n",
        "print()\n",
        "print(data)\n",
        "print('===========================================================================================================')\n",
        "\n",
        "# Gather some statistics about the graph.\n",
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of node features: {data.num_features}')\n",
        "print(f'Number of {classes_mapping} classes: {data.num_classes}')\n",
        "print(f'Class distritions: {Counter(data.y.numpy())}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "print(f'Nodes indices: {train_indices}')\n",
        "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "print(f'Training node indices: {data.train_idx}')\n",
        "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
        "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
        "print(f'Has edge weights: {data.edge_attr}')\n",
        "print(f'Has self-loops: {data.has_self_loops()}')\n",
        "print(f'Is directed: {data.is_directed()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ucyeYkxqYU5"
      },
      "source": [
        "# The Trainer class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JdeDDnoAqYU6"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "from dataclasses import dataclass\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam, lr_scheduler\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "@dataclass\n",
        "class RunConfig:  # default parameters from the paper and official implementation\n",
        "    learning_rate: float = 0.01\n",
        "    num_epochs: int = 200\n",
        "    weight_decay: float = 5e-4\n",
        "    num_warmup_steps: int = 0\n",
        "    save_each_epoch: bool = False\n",
        "    output_dir: str = \".\"\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def train(self, features, train_labels, val_labels, edge_index, edge_weights, device, run_config, log=True, eval_train=False):\n",
        "        self.model = self.model.to(device)\n",
        "        features = features.to(device)\n",
        "        train_labels = train_labels.to(device)\n",
        "        val_labels = val_labels.to(device)\n",
        "        edge_index = edge_index.to(device)  # edhe list and weight\n",
        "        edge_weights = edge_weights.to(device)\n",
        "\n",
        "        optimizer = Adam(self.model.parameters(), lr=run_config.learning_rate, weight_decay=run_config.weight_decay)\n",
        "\n",
        "        # https://huggingface.co/transformers/_modules/transformers/optimization.html#get_linear_schedule_with_warmup\n",
        "        def lr_lambda(current_step: int):\n",
        "            if current_step < run_config.num_warmup_steps:\n",
        "                return float(current_step) / float(max(1, run_config.num_warmup_steps))\n",
        "            return max(0.0, float(run_config.num_epochs - current_step) /\n",
        "                       float(max(1, run_config.num_epochs - run_config.num_warmup_steps)))\n",
        "\n",
        "        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "        if log:\n",
        "            print(\"Training started:\")\n",
        "            print(f\"\\tNum Epochs = {run_config.num_epochs}\")\n",
        "\n",
        "        best_loss, best_model_accuracy = float(\"inf\"), 0\n",
        "        best_model_state_dict = None\n",
        "        if log: train_iterator = tqdm(range(0, int(run_config.num_epochs)))\n",
        "        else: train_iterator = range(0, int(run_config.num_epochs))\n",
        "        train_logs = {'train loss' : [], 'train acc' : [], 'train mcc' : [], 'val loss' : [],  'val acc' : [], 'val mcc' : []}\n",
        "        for epoch in train_iterator:\n",
        "            self.model.train()\n",
        "            outputs = self.model(features, edge_index, edge_weights, train_labels)\n",
        "            loss = outputs[1]\n",
        "\n",
        "            self.model.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            if eval_train: train_loss, train_accuracy, train_mcc, _ , _ = self.evaluate(features, train_labels, edge_index, edge_weights, device)\n",
        "            val_loss, val_accuracy, val_mcc, _ , _= self.evaluate(features, val_labels, edge_index, edge_weights, device)\n",
        "            if log: train_iterator.set_description(f\"Training loss = {loss.item():.4f}, \" f\"val loss = {val_loss:.4f}, val acc = {val_accuracy:.2f}, val mcc = {val_mcc:.2f}\")\n",
        "\n",
        "            save_best_model = val_loss < best_loss\n",
        "            if save_best_model:\n",
        "                best_loss = val_loss\n",
        "                best_model_accuracy = val_accuracy\n",
        "                best_model_state_dict = copy.deepcopy(self.model.state_dict())\n",
        "            if save_best_model or run_config.save_each_epoch or epoch + 1 == run_config.num_epochs:\n",
        "                output_dir = os.path.join(run_config.output_dir, f\"Epoch_{epoch + 1}\")\n",
        "                #self.save(output_dir)\n",
        "            if eval_train:\n",
        "                train_logs['train loss'].append(train_loss)\n",
        "                train_logs['train acc'].append(train_accuracy)\n",
        "                train_logs['train mcc'].append(train_mcc)\n",
        "            train_logs['val loss'].append(val_loss)\n",
        "            train_logs['val acc'].append(val_accuracy)\n",
        "            train_logs['val mcc'].append(val_mcc)\n",
        "        if log:\n",
        "            print(f\"Best model val CE loss = {best_loss:.4f}, best model val accuracy = {best_model_accuracy:.2f}\")\n",
        "        # reloads the best model state dict, bit hacky :P\n",
        "        self.model.load_state_dict(best_model_state_dict)\n",
        "        return train_logs \n",
        "\n",
        "    def evaluate(self, features, test_labels, edge_index, edge_weights, device):\n",
        "        features = features.to(device)\n",
        "        test_labels = test_labels.to(device)\n",
        "        edge_index = edge_index.to(device)  # edhe list and weight\n",
        "        edge_weights = edge_weights.to(device)\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "        outputs = self.model(features, edge_index, edge_weights, test_labels)\n",
        "        ce_loss = outputs[1].item()\n",
        "\n",
        "        ignore_label = nn.CrossEntropyLoss().ignore_index\n",
        "        predicted_label = torch.max(outputs[0], dim=1).indices[test_labels != ignore_label]\n",
        "        true_label = test_labels[test_labels != -100]\n",
        "        accuracy = torch.mean((true_label == predicted_label).type(torch.FloatTensor)).item()\n",
        "        mcc = metrics.matthews_corrcoef(true_label, predicted_label)\n",
        "        cm = metrics.confusion_matrix(true_label, predicted_label)\n",
        "        return ce_loss, accuracy, mcc, cm, predicted_label \n",
        "\n",
        "    def save(self, output_dir):\n",
        "        if not os.path.isdir(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        model_path = os.path.join(output_dir, \"model.pth\")\n",
        "        torch.save(self.model.state_dict(), model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwBeBCdqqYU7"
      },
      "source": [
        "# The model GNN "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZE2bxnYwqYU8"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import GCNConv, GATConv, ChebConv\n",
        "import torch.nn as nn\n",
        "from torch_geometric.nn import GraphUNet\n",
        "from torch_geometric.utils import dropout_adj\n",
        "\n",
        "use_gdc = True\n",
        "weights=torch.tensor([round(Counter(data.y.numpy())[classes_mapping['NE']]/len(data.y),2), round(Counter(data.y.numpy())[classes_mapping['E']]/len(data.y),2)])\n",
        "#weights = None\n",
        "\n",
        "def reset_weights(m):\n",
        "  '''\n",
        "    Try resetting model weights to avoid\n",
        "    weight leakage.\n",
        "  '''\n",
        "  for layer in m.children():\n",
        "   if hasattr(layer, 'reset_parameters'):\n",
        "    #print(f'Reset trainable parameters of layer = {layer}')\n",
        "    layer.reset_parameters()\n",
        "\n",
        "class ChebNetGCN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_hidden_layers=0, dropout=0.1, residual=False, k=2):\n",
        "        super(ChebNetGCN, self).__init__()\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.residual = residual\n",
        "\n",
        "        self.input_conv = ChebConv(input_size, hidden_size, k)\n",
        "        self.hidden_convs = nn.ModuleList([ChebConv(hidden_size, hidden_size, k) for _ in range(num_hidden_layers)])\n",
        "        self.output_conv = ChebConv(hidden_size, output_size, k)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, edge_weight: torch.Tensor, labels: torch.Tensor = None):\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.input_conv(x, edge_index, edge_weight))\n",
        "        for conv in self.hidden_convs:\n",
        "            if self.residual:\n",
        "                x = F.relu(conv(x, edge_index, edge_weight)) + x\n",
        "            else:\n",
        "                x = F.relu(conv(x, edge_index, edge_weight))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.output_conv(x, edge_index, edge_weight)\n",
        "\n",
        "        if labels is None:\n",
        "            return x\n",
        "\n",
        "        loss = nn.CrossEntropyLoss()(x, labels)\n",
        "        return x, loss\n",
        "\n",
        "class GAT(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, dropout=0.1):\n",
        "        super(GAT, self).__init__()\n",
        "        torch.manual_seed(42)\n",
        "\n",
        "        self.conv1 = GATConv(input_size, hidden_size, heads=hidden_size, edge_dim=1, dropout=0.6)\n",
        "        # On the Pubmed dataset, use heads=8 in conv2.\n",
        "        self.conv2 = GATConv(hidden_size * hidden_size, output_size, heads=1, edge_dim=1, concat=False,\n",
        "                             dropout=0.6)\n",
        "        self.elu = nn.ELU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, edge_weight: torch.Tensor, labels: torch.Tensor = None):\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv1(x, edge_index, edge_weight)\n",
        "        x = self.elu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv2(x, edge_index, edge_weight)\n",
        "        if labels is None:\n",
        "            return x\n",
        "\n",
        "        loss = nn.CrossEntropyLoss(weight=weights)(x, labels)\n",
        "        return x, loss\n",
        "\n",
        "class OneLayerGCN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, dropout=0.1):\n",
        "        super(OneLayerGCN, self).__init__()\n",
        "        torch.manual_seed(42)\n",
        "        self.conv = GCNConv(input_size, output_size, cached=True, improved=True, add_self_loops=True, normalize=not use_gdc)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, edge_weight: torch.Tensor, labels: torch.Tensor = None):\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv(x, edge_index, edge_weight)\n",
        "        if labels is None:\n",
        "            return x\n",
        "\n",
        "        loss = nn.CrossEntropyLoss(weight=weights)(x, labels)\n",
        "        return x, loss\n",
        "\n",
        "class TwoLayerGCN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, dropout=0.1):\n",
        "        super(TwoLayerGCN, self).__init__()\n",
        "        torch.manual_seed(42)\n",
        "        self.conv1 = GCNConv(input_size, hidden_size, cached=True, improved=True, add_self_loops=True, normalize=not use_gdc)\n",
        "        self.conv2 = GCNConv(hidden_size, output_size, cached=True, improved=True, add_self_loops=True, normalize=not use_gdc)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, edge_weight: torch.Tensor, labels: torch.Tensor = None):\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv1(x, edge_index, edge_weight)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv2(x, edge_index, edge_weight)\n",
        "        if labels is None:\n",
        "            return x\n",
        "\n",
        "        loss = nn.CrossEntropyLoss(weight=weights)(x, labels)\n",
        "        return x, loss\n",
        "\n",
        "class ThreeLayerGCN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, dropout=0.1):\n",
        "        super(ThreeLayerGCN, self).__init__()\n",
        "        torch.manual_seed(42)\n",
        "        self.conv1 = GCNConv(input_size, hidden_size, cached=True, improved=True, add_self_loops=True, normalize=not use_gdc)\n",
        "        self.conv2 = GCNConv(hidden_size, hidden_size, cached=True, improved=True, add_self_loops=True, normalize=not use_gdc)\n",
        "        self.conv3 = GCNConv(hidden_size, output_size, cached=True, improved=True, add_self_loops=True, normalize=not use_gdc)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, edge_weight: torch.Tensor, labels: torch.Tensor = None):\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv1(x, edge_index, edge_weight)\n",
        "        x = self.relu1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv2(x, edge_index, edge_weight)\n",
        "        x = self.relu2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv3(x, edge_index, edge_weight)\n",
        "        if labels is None:\n",
        "            return x\n",
        "\n",
        "        loss = nn.CrossEntropyLoss(weight=weights)(x, labels)\n",
        "        return x, loss\n",
        "\n",
        "class GUNet(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, dropout=0.6):\n",
        "        super().__init__()\n",
        "        pool_ratios = [2000 / data.num_nodes, 0.5]\n",
        "        self.unet = GraphUNet(input_size, hidden_size, output_size,\n",
        "                              depth=3, pool_ratios=pool_ratios)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, edge_weight: torch.Tensor, labels: torch.Tensor = None):\n",
        "        edge_index, _ = dropout_adj(edge_index, edge_attr=edge_weight, p=0.2,\n",
        "                                    force_undirected=True,\n",
        "                                    num_nodes=data.num_nodes,\n",
        "                                    training=self.training)\n",
        "        x = F.dropout(data.x, p=0.92, training=self.training)\n",
        "\n",
        "        x = self.unet(x, edge_index)\n",
        "        if labels is None:\n",
        "            return x\n",
        "\n",
        "        loss = nn.CrossEntropyLoss(weight=weights)(x, labels)\n",
        "        return x, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gmpV5So5_rV"
      },
      "source": [
        "# k-fold validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l89paGzXqYU9",
        "outputId": "cfa048ea-84ce-494b-9085-4a9bc703d7db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5-fold:  20%|██        | 1/5 [00:26<01:47, 26.80s/it]"
          ]
        }
      ],
      "source": [
        "#@title Choose GNN { form-width: \"20%\" }\n",
        "netmodel = \"OneLayerGCN\" #@param [\"OneLayerGCN\", \"TwoLayerGCN\", \"ChebNetGCN\"]\n",
        "epochs = 1000 #@param {type:\"slider\", min:10, max:1000, step:10}\n",
        "def set_labels(initial_labels, set_mask, ignore_label):\n",
        "    initial_labels[~set_mask] = ignore_label\n",
        "    return initial_labels\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "set_seed(1)\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, KFold, train_test_split\n",
        "from sklearn.metrics import *\n",
        "from tqdm import tqdm\n",
        "nfolds = 5\n",
        "kf = KFold(n_splits=nfolds)\n",
        "accuracies = []\n",
        "mccs = []\n",
        "cma = np.array([[0,0],[0,0]])\n",
        "columns_names = [\"Accuracy\",\"BA\", \"Sensitivity\", \"Specificity\",\"MCC\", 'CM']\n",
        "scores = pd.DataFrame(columns=columns_names)\n",
        "mm = np.array([], dtype=np.int)\n",
        "predictions = np.array([])\n",
        "for fold, (train_index, test_index) in enumerate(tqdm(kf.split(np.arange(data.num_nodes)), total=kf.get_n_splits(), desc=f\"{nfolds}-fold\")):\n",
        "    mm = np.concatenate((mm, test_index))\n",
        "    train_labels = y[train_index]\n",
        "    train_index, val_index = train_test_split(train_index, test_size=0.025, stratify=train_labels)\n",
        "    tr_index  = torch.tensor(train_index)\n",
        "    val_index  = torch.tensor(val_index)\n",
        "    ts_index = torch.tensor(test_index)\n",
        "    train_mask = torch.BoolTensor([False]*data.num_nodes)\n",
        "    val_mask = torch.BoolTensor([False]*data.num_nodes)\n",
        "    test_mask = torch.BoolTensor([False]*data.num_nodes)\n",
        "    train_mask.scatter_(0, tr_index, True)\n",
        "    val_mask.scatter_(0, val_index, True)\n",
        "    test_mask.scatter_(0, ts_index, True)\n",
        "\n",
        "    ignore_index = nn.CrossEntropyLoss().ignore_index  # = -100, used to ignore not allowed labels in CE loss\n",
        "    train_labels = set_labels(data.y.clone(), train_mask, ignore_index)\n",
        "    val_labels = set_labels(data.y.clone(), val_mask, ignore_index)\n",
        "    test_labels = set_labels(data.y.clone(), test_mask, ignore_index)\n",
        "    # training parameters\n",
        "    run_config = RunConfig(learning_rate=0.01, num_epochs=epochs, weight_decay=5e-4)\n",
        "    model = globals()[netmodel](input_size=data.x.shape[1],hidden_size=16,output_size=data.num_classes,dropout=0)\n",
        "\n",
        "    # training\n",
        "    trainer = Trainer(model)\n",
        "    trainer.train(data.x, train_labels, val_labels, data.edge_index, data.edge_attr, device, run_config, log=False)\n",
        "\n",
        "    # evaluating\n",
        "    ce_loss, accuracy, mcc, cm, preds = trainer.evaluate(data.x, test_labels, data.edge_index, data.edge_attr, device)\n",
        "    accuracies.append(accuracy)\n",
        "    mccs.append(mcc)\n",
        "    predictions = np.concatenate((predictions, preds.ravel()))\n",
        "    cma += cm\n",
        "    true_label = test_labels[test_labels != -100]\n",
        "    scores = scores.append(pd.DataFrame([[accuracy_score(true_label.cpu().numpy(), preds.cpu().numpy()), balanced_accuracy_score(true_label.cpu().numpy(), preds.cpu().numpy()), \n",
        "        cm[0,0]/(cm[0,0]+cm[0,1]), cm[1,1]/(cm[1,0]+cm[1,1]), \n",
        "        matthews_corrcoef(true_label.cpu().numpy(), preds.cpu().numpy()), cm]], columns=columns_names, index=[fold]))\n",
        "df_scores = pd.DataFrame(scores.mean(axis=0)).T\n",
        "df_scores.index=[f'{netmodel}']\n",
        "df_scores['CM'] = [cma]\n",
        "df_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TsJPJYWVKWo"
      },
      "source": [
        "# Print predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "t7Q2gF8t4p12",
        "outputId": "36e73a14-2275-473d-e381-ddd463e68e0e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-562794c1-e432-443b-be74-ec734732f00c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CS0_vs_CS6-9</th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ENSG00000001036</th>\n",
              "      <td>NE</td>\n",
              "      <td>NE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ENSG00000001461</th>\n",
              "      <td>NE</td>\n",
              "      <td>NE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ENSG00000001561</th>\n",
              "      <td>NE</td>\n",
              "      <td>NE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ENSG00000001630</th>\n",
              "      <td>NE</td>\n",
              "      <td>NE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ENSG00000001631</th>\n",
              "      <td>NE</td>\n",
              "      <td>NE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ENSG00000288257</th>\n",
              "      <td>NE</td>\n",
              "      <td>NE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ENSG00000288283</th>\n",
              "      <td>NE</td>\n",
              "      <td>NE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ENSG00000288359</th>\n",
              "      <td>NE</td>\n",
              "      <td>NE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ENSG00000288407</th>\n",
              "      <td>NE</td>\n",
              "      <td>NE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ENSG00000288478</th>\n",
              "      <td>NE</td>\n",
              "      <td>NE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2954 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-562794c1-e432-443b-be74-ec734732f00c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-562794c1-e432-443b-be74-ec734732f00c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-562794c1-e432-443b-be74-ec734732f00c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                CS0_vs_CS6-9 predictions\n",
              "name                                    \n",
              "ENSG00000001036           NE          NE\n",
              "ENSG00000001461           NE          NE\n",
              "ENSG00000001561           NE          NE\n",
              "ENSG00000001630           NE          NE\n",
              "ENSG00000001631           NE          NE\n",
              "...                      ...         ...\n",
              "ENSG00000288257           NE          NE\n",
              "ENSG00000288283           NE          NE\n",
              "ENSG00000288359           NE          NE\n",
              "ENSG00000288407           NE          NE\n",
              "ENSG00000288478           NE          NE\n",
              "\n",
              "[2954 rows x 2 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p = np.zeros(len(y))\n",
        "p[mm] = predictions\n",
        "labels['predictions'] = ['NE' if x>0 else 'E' for x in p]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULfO6TuTYgzT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "EssentialGenes_GNN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "bc6e667b201477635ba32fc377e71e93fe0ce3fc2d2fb508931525558f52d375"
    },
    "kernelspec": {
      "display_name": "Python 3.8.3 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
